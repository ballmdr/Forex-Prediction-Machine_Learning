{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Forex Pytorch RNN LSTM GRU.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ballmdr/Forex-Prediction-Machine_Learning/blob/master/Forex_Pytorch_RNN_LSTM_GRU.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GTr87mQimrTu",
        "colab_type": "code",
        "outputId": "c35d50de-f4b5-4e1e-8417-98c7e409e037",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 479
        }
      },
      "source": [
        "!pip install fxcmpy"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting fxcmpy\n",
            "  Downloading https://files.pythonhosted.org/packages/14/12/d466ac750941e4a0fe75c5e7935713a74a9d7474cb27bc472e0a757b4b48/fxcmpy-1.2.4-py3-none-any.whl\n",
            "Requirement already satisfied: requests[socks] in /usr/local/lib/python3.6/dist-packages (from fxcmpy) (2.21.0)\n",
            "Collecting configparser (from fxcmpy)\n",
            "  Downloading https://files.pythonhosted.org/packages/ba/05/6c96328e92e625fc31445d24d75a2c92ef9ba34fc5b037fe69693c362a0d/configparser-3.7.4-py2.py3-none-any.whl\n",
            "Collecting socketIO-client (from fxcmpy)\n",
            "  Downloading https://files.pythonhosted.org/packages/12/d4/abeb2596c2f16276c66910362b27d04b8d2cf12a746dcccf1d00de3f691b/socketIO-client-0.7.2.tar.gz\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.6/dist-packages (from fxcmpy) (0.24.2)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests[socks]->fxcmpy) (2019.6.16)\n",
            "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests[socks]->fxcmpy) (3.0.4)\n",
            "Requirement already satisfied: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests[socks]->fxcmpy) (1.24.3)\n",
            "Requirement already satisfied: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests[socks]->fxcmpy) (2.8)\n",
            "Requirement already satisfied: PySocks!=1.5.7,>=1.5.6; extra == \"socks\" in /usr/local/lib/python3.6/dist-packages (from requests[socks]->fxcmpy) (1.7.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from socketIO-client->fxcmpy) (1.12.0)\n",
            "Collecting websocket-client (from socketIO-client->fxcmpy)\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/29/19/44753eab1fdb50770ac69605527e8859468f3c0fd7dc5a76dd9c4dbd7906/websocket_client-0.56.0-py2.py3-none-any.whl (200kB)\n",
            "\u001b[K     |████████████████████████████████| 204kB 8.0MB/s \n",
            "\u001b[?25hRequirement already satisfied: python-dateutil>=2.5.0 in /usr/local/lib/python3.6/dist-packages (from pandas->fxcmpy) (2.5.3)\n",
            "Requirement already satisfied: pytz>=2011k in /usr/local/lib/python3.6/dist-packages (from pandas->fxcmpy) (2018.9)\n",
            "Requirement already satisfied: numpy>=1.12.0 in /usr/local/lib/python3.6/dist-packages (from pandas->fxcmpy) (1.16.4)\n",
            "Building wheels for collected packages: socketIO-client\n",
            "  Building wheel for socketIO-client (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Stored in directory: /root/.cache/pip/wheels/bd/5d/9f/ebc0c223ec59641877c817eb10442627e69af88c126f1f53a8\n",
            "Successfully built socketIO-client\n",
            "Installing collected packages: configparser, websocket-client, socketIO-client, fxcmpy\n",
            "Successfully installed configparser-3.7.4 fxcmpy-1.2.4 socketIO-client-0.7.2 websocket-client-0.56.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KB2wBmhcwl_A",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import fxcmpy\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "sns.set()\n",
        "%matplotlib inline\n",
        "\n",
        "def connect():\n",
        "    return fxcmpy.fxcmpy(access_token=access_token, server=server)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "um-6M_LNw0Rv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "access_token = '82e41ea2bcf020754f67aeb835e9ad617dbc5427'\n",
        "server = 'demo'\n",
        "symbol = 'BTCUSD'\n",
        "symbol2 = 'BTC/USD'\n",
        "target_windows = 5\n",
        "digits = 1\n",
        "ratio = 100\n",
        "n_prices = 2000"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TK4QhqlJ46Ob",
        "colab_type": "code",
        "outputId": "51716331-2273-4ad2-e02f-f0b5498fa933",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "con = connect()"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "|WARNING|2019-07-28 01:59:48,481|Default account set to 96112465, to change use set_default_account().\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7oZt1uuEw81f",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FFmL-2Xe4p_S",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def dfProcess(df):\n",
        "# Short-Term\n",
        "# ใช้ค่า 3, 5, 8, 10, 12, or 15.\n",
        "# Long-Term\n",
        "# ใช้ค่า 30, 35, 40, 45, 50, or 60.\n",
        "  df['ma3'] = np.round(df.close.rolling(3).mean(), 5)\n",
        "  df['ma5'] = np.round(df.close.rolling(5).mean(), 5)\n",
        "  df['ma8'] = np.round(df.close.rolling(8).mean(), 5)\n",
        "  df['ma10'] = np.round(df.close.rolling(10).mean(), 5)\n",
        "  df['ma12'] = np.round(df.close.rolling(12).mean(), 5)\n",
        "  df['ma15'] = np.round(df.close.rolling(15).mean(), 5)\n",
        "  #df['ma20'] = np.round(df.close.rolling(20).mean(), 5)\n",
        "  #df['ma7_shift3'] = df.ma7.shift(-3)\n",
        "  #df['ma10_shift3'] = df.ma10.shift(-3)\n",
        "  #df['close_shift3'] = df.close.shift(-3)\n",
        "  df['close_diff_pip'] = - df.close.diff(-target_windows) * digits\n",
        "  \n",
        "  arr = ['0', '1', '2', '3', '4']\n",
        "  for i in range(1, target_windows):\n",
        "    df[arr[i]] = - df.close.diff(-i) * digits\n",
        "    \n",
        "  df.dropna(inplace=True)\n",
        "\n",
        "  #df['close_target_percent'] = np.round((df['close_diff_pip']*digits)/df.close, 2) * 100\n",
        "  #df['7_10_target_percent'] = np.round(((df['ma7_shift3']-df['ma10_shift3'])*digits)/df['ma10_shift3'], 2)\n",
        "  #df['5_7_target_percent'] = np.round(((df.ma5-df.ma7)*digits)/df.ma7, 2)\n",
        "  \n",
        "\n",
        "  df['Target'] = np.ones(len(df))\n",
        "  # df['Target'].loc[(df['close_target_percent'] > 9) & (df['7_10_target_percent'] > 1) & (df['5_7_target_percent'] > 1)] = 2\n",
        "  # df['Target'].loc[(df['close_target_percent'] < -9) & (df['7_10_target_percent'] < -1) & (df['5_7_target_percent'] < -1)] = 0\n",
        "  df['Target'].loc[(df['close_diff_pip'] > ratio) &\n",
        "                   (df['1'] > -ratio) &\n",
        "                   (df['2'] > -ratio) &\n",
        "                   (df['3'] > -ratio) &\n",
        "                   (df['4'] > -ratio)\n",
        "                  ] = 2\n",
        "  df['Target'].loc[(df['close_diff_pip'] < -ratio) &\n",
        "                   (df['1'] < ratio) &\n",
        "                   (df['2'] < ratio) &\n",
        "                   (df['3'] < ratio) &\n",
        "                   (df['4'] < ratio)                    \n",
        "                  ] = 0\n",
        "  print(df.Target.value_counts())\n",
        "\n",
        "  df.drop(['bidopen', 'bidclose', 'bidhigh', 'askopen', 'askclose', 'askhigh', 'bidlow', 'asklow', 'tickqty'], axis=1, inplace=True)\n",
        "  df.dropna(inplace=True)\n",
        "  print(df.head())\n",
        "  print(df.shape)\n",
        "  \n",
        "  print(df.info())\n",
        "  \n",
        "  return df\n",
        "\n",
        "\n",
        "def getXY(df, windows):\n",
        "\n",
        "  X = []\n",
        "  Y = []\n",
        "  for i in range(len(df)-(windows+1)):\n",
        "    \n",
        "\n",
        "    fig = plt.figure(frameon=False) \n",
        "    fig.set_size_inches(3,2)\n",
        "    ax = plt.Axes(fig, [0., 0., 1., 1.])\n",
        "    ax.set_axis_off()\n",
        "    fig.add_axes(ax)\n",
        "\n",
        "    _df = df.iloc[i:windows]\n",
        "    plt.plot(_df.ma3, color='red')\n",
        "    plt.plot(_df.ma5, color='blue')\n",
        "    plt.plot(_df.ma8, color='green')\n",
        "    plt.plot(_df.ma10, color='orange')\n",
        "    plt.plot(_df.ma12, color='black')\n",
        "    plt.plot(_df.ma15, color='purple')\n",
        "    #plt.plot(_df.open, color='black')\n",
        "   # plt.plot(_df.close, color='purple')\n",
        "\n",
        "    plt.savefig('tmp2.png')\n",
        "\n",
        "    plt.close()\n",
        "\n",
        "    img = plt.imread('tmp2.png')\n",
        "    new_img = resize(img, (100,150))\n",
        "    #print(new_img.shape)\n",
        "    if i % 1000 == 0:\n",
        "      print(i)\n",
        "      plt.imshow(new_img)\n",
        "      plt.show()\n",
        "      print(i, ' - ', windows)\n",
        "      print('target: ', df.Target.iloc[windows-1])\n",
        "    X.append(new_img)\n",
        "    Y.append(df.Target.iloc[windows-1])\n",
        "\n",
        "    windows += 1\n",
        "\n",
        "  return X, Y\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SnqjLTdB4rRQ",
        "colab_type": "code",
        "outputId": "06ac1579-ac91-4de4-917b-23356e682462",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 731
        }
      },
      "source": [
        "df = con.get_candles(symbol2, period='H4', number=n_prices)\n",
        "df['close'] = (df.bidclose + df.askclose) / 2\n",
        "df = dfProcess(df)\n",
        "\n",
        "#df['close'] = (df.close - df.close.mean()) / (df.close.max() - df.close.min())\n",
        "#print(df['close'].head())\n",
        "\n",
        "split = int(len(close) * 0.60)\n",
        "train_data = df.iloc[:split].drop(['Target'], axis=1).values\n",
        "train_target = df.iloc[:split]['Target'].values\n",
        "test_data = df.iloc[split:].drop(['Target'], axis=1).values\n",
        "test_target = df.iloc[split:]['Target'].values\n",
        "\n",
        "minmax = MinMaxScaler()\n",
        "train_data = minmax.fit_transform(train_data)\n",
        "test_data = minmax.transform(test_data)\n",
        "print(train_data.shape)\n",
        "print(train_target.shape)\n",
        "print(test_data.shape)\n",
        "print(test_target.shape)"
      ],
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2.0    191\n",
            "1.0    181\n",
            "0.0    115\n",
            "Name: Target, dtype: int64\n",
            "                       close         ma3      ma5  ...       3       4  Target\n",
            "date                                               ...                        \n",
            "2019-04-02 02:00:00  4169.00  4147.41667  4138.55  ...  651.00  583.75     2.0\n",
            "2019-04-02 06:00:00  4760.00  4354.83333  4267.00  ...   -7.25  152.75     2.0\n",
            "2019-04-02 10:00:00  4810.00  4579.66667  4402.45  ...  102.75  275.75     2.0\n",
            "2019-04-02 14:00:00  4820.00  4796.66667  4538.90  ...  265.75  166.25     2.0\n",
            "2019-04-02 18:00:00  4752.75  4794.25000  4662.35  ...  233.50  230.50     2.0\n",
            "\n",
            "[5 rows x 13 columns]\n",
            "(487, 13)\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "DatetimeIndex: 487 entries, 2019-04-02 02:00:00 to 2019-07-26 02:00:00\n",
            "Data columns (total 13 columns):\n",
            "close             487 non-null float64\n",
            "ma3               487 non-null float64\n",
            "ma5               487 non-null float64\n",
            "ma8               487 non-null float64\n",
            "ma10              487 non-null float64\n",
            "ma12              487 non-null float64\n",
            "ma15              487 non-null float64\n",
            "close_diff_pip    487 non-null float64\n",
            "1                 487 non-null float64\n",
            "2                 487 non-null float64\n",
            "3                 487 non-null float64\n",
            "4                 487 non-null float64\n",
            "Target            487 non-null float64\n",
            "dtypes: float64(13)\n",
            "memory usage: 53.3 KB\n",
            "None\n",
            "(292, 12)\n",
            "(292,)\n",
            "(195, 12)\n",
            "(195,)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/pandas/core/indexing.py:190: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
            "  self._setitem_with_indexer(indexer, value)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Kw4Zk6hSFnxq",
        "colab_type": "code",
        "outputId": "c565c866-3014-4981-b00c-f780ff6ea947",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        }
      },
      "source": [
        "test_target"
      ],
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([1., 1., 1., 1., 2., 2., 2., 2., 2., 2., 1., 1., 2., 2., 1., 2., 2.,\n",
              "       2., 1., 2., 2., 2., 2., 2., 2., 2., 2., 1., 0., 0., 0., 0., 0., 1.,\n",
              "       1., 1., 1., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2.,\n",
              "       2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2.,\n",
              "       2., 2., 1., 0., 0., 0., 0., 0., 1., 1., 2., 1., 1., 1., 1., 0., 0.,\n",
              "       0., 0., 0., 1., 1., 1., 1., 2., 2., 2., 2., 2., 1., 2., 2., 2., 0.,\n",
              "       0., 1., 0., 0., 1., 2., 1., 1., 1., 2., 2., 2., 2., 2., 2., 2., 1.,\n",
              "       1., 1., 2., 2., 1., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 1., 1.,\n",
              "       2., 1., 1., 1., 1., 0., 2., 2., 1., 0., 0., 0., 0., 0., 0., 1., 2.,\n",
              "       2., 2., 2., 1., 1., 2., 2., 2., 2., 1., 0., 0., 1., 1., 1., 2., 0.,\n",
              "       0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 0., 0., 1., 2., 2., 2., 1.,\n",
              "       2., 0., 0., 0., 0., 0., 1., 1.])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 59
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V1tKxr2nyyu9",
        "colab_type": "code",
        "outputId": "929ffe2f-739e-4f0c-c06c-5cf8c6c8ce70",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 409
        }
      },
      "source": [
        "class RNN(nn.Module):\n",
        "    def __init__(self, hidden, K, input_size):\n",
        "        super(RNN, self).__init__()\n",
        "        \n",
        "        self.linearH = nn.Linear(input_size + hidden, hidden)\n",
        "        self.linearO = nn.Linear(input_size + hidden, K)\n",
        "        self.softmax = nn.LogSoftmax(dim=1)\n",
        "        \n",
        "    def forward(self, x, h):\n",
        "        x = torch.cat((x, h), 1)\n",
        "        h = torch.tanh(self.linearH(x))\n",
        "        out = self.softmax(self.linearO(x))\n",
        "        \n",
        "        return out, h\n",
        "      \n",
        "      \n",
        "class LSTM(nn.Module):\n",
        "  def __init__(self, hidden, output_size, vocab_size):\n",
        "    super(LSTM, self).__init__()\n",
        "    \n",
        "    self.linearFt = nn.Linear(vocab_size + hidden, hidden)\n",
        "    self.linearIt = nn.Linear(vocab_size + hidden, hidden)\n",
        "    self.linearCt1 = nn.Linear(vocab_size + hidden, hidden)\n",
        "    self.linearOt = nn.Linear(vocab_size + hidden, hidden)\n",
        "    self.linearO = nn.Linear(vocab_size + hidden, output_size)\n",
        "    \n",
        "    self.softmax = nn.LogSoftmax(dim=1)\n",
        "    \n",
        "  def forward(self, x, h, c):\n",
        "    combined = torch.cat((x, h), 1)\n",
        "    ft = torch.sigmoid(self.linearFt(combined))\n",
        "    it = torch.sigmoid(self.linearIt(combined))\n",
        "    ct1 = torch.tanh(self.linearCt1(combined))\n",
        "    c = (ft*c) + (it * ct1)\n",
        "    \n",
        "    ot = torch.sigmoid(self.linearOt(combined))\n",
        "    h = ot * torch.tanh(c)\n",
        "    \n",
        "    out = self.softmax(self.linearO(combined))\n",
        "    \n",
        "    return out, h, c\n",
        "\n",
        "  \n",
        "class GRU(nn.Module):\n",
        "  \n",
        "  def __init__(self, hidden, output_size, input_size):\n",
        "    super(GRU, self).__init__()\n",
        "    \n",
        "    self.linearZt = nn.Linear(input_size + hidden, hidden)\n",
        "    self.linearRt = nn.Linear(input_size + hidden, hidden)\n",
        "    self.linearHt = nn.Linear(input_size + hidden, hidden)\n",
        "    \n",
        "    self.linearO = nn.Linear(input_size + hidden, output_size)\n",
        "    \n",
        "    self.softmax = nn.LogSoftmax(dim=1)\n",
        "    \n",
        "  def forward(self, x, h):\n",
        "    combined = torch.cat((x, h), 1)\n",
        "    zt = torch.sigmoid(self.linearZt(combined))\n",
        "    rt = torch.sigmoid(self.linearRt(combined))\n",
        "    combined2 = torch.cat((x, rt*h), 1)\n",
        "    ht = torch.tanh(self.linearHt(combined2))\n",
        "    h = (1-zt) * h + zt * ht\n",
        "    \n",
        "    out = self.softmax(self.linearO(combined))\n",
        "  \n",
        "    return out, h\n",
        "  \n",
        "windows = 6\n",
        "input_size = 12\n",
        "hidden = 128\n",
        "K = 3\n",
        "learning_rate = 0.05\n",
        "epochs = 15000\n",
        "train_loss = []\n",
        "test_loss = []\n",
        "\n",
        "\n",
        "model = GRU(hidden, K, input_size)\n",
        "model.cuda()\n",
        "loss_fn = nn.NLLLoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
        "scheduler = torch.optim.lr_scheduler.MultiStepLR(optimizer, milestones=[2000, 4000, 6000, 8000, 10000, 12000, 14000], gamma=0.1)\n",
        "N = len(train_data)-(windows+1)\n",
        "print(N)\n",
        "\n",
        "for e in range(epochs):\n",
        "    model.train()\n",
        "    running_loss = 0.0\n",
        "    testing_loss = 0.0\n",
        "    \n",
        "    \n",
        "    for i in range(N):\n",
        "        \n",
        "        inputs = train_data[i:i+windows]\n",
        "        y = train_target[(i+windows)-1]\n",
        "        #print(i, ' Input: ', inputs, ' Target: ', y, ' ', train_data[windows-1])\n",
        "        \n",
        "        h = torch.zeros([1, hidden], dtype=torch.float32, device='cuda')\n",
        "        c = torch.zeros([1, hidden], dtype=torch.float32, device='cuda')\n",
        "        \n",
        "        y_tensor = torch.tensor(y, dtype=torch.long, device='cuda')\n",
        "        \n",
        "        #print('y: ', y_tensor)\n",
        "        \n",
        "        optimizer.zero_grad()\n",
        "        \n",
        "        for w in inputs:\n",
        "          #print(w)\n",
        "          x_tensor = torch.tensor(w, dtype=torch.float32, device='cuda')\n",
        "          x_tensor = x_tensor.view(1,-1)\n",
        "          out, h = model(x_tensor, h)\n",
        "\n",
        "        #print('out: ', out)\n",
        "        loss = loss_fn(out, y_tensor.unsqueeze(0))\n",
        "        loss.backward(retain_graph=True)\n",
        "        optimizer.step()\n",
        "        running_loss += loss.item()\n",
        "        \n",
        "\n",
        "    run_loss = running_loss / N\n",
        "    train_loss.append(run_loss)\n",
        "    scheduler.step()\n",
        "\n",
        "    model.eval()\n",
        "    test_count = 5\n",
        "    for j in range(test_count):\n",
        "        index = np.random.randint(0, len(test_data)-(windows+1))\n",
        "        #print('index: ', index)\n",
        "        h = torch.zeros([1, hidden], dtype=torch.float32, device='cuda')\n",
        "        c = torch.zeros([1, hidden], dtype=torch.float32, device='cuda')\n",
        "        \n",
        "        inputs = test_data[index:index+windows]\n",
        "        y = test_target[(index+windows)-1]\n",
        "        y_tensor = torch.tensor(y, dtype=torch.long, device='cuda')\n",
        "\n",
        "        for w in inputs:\n",
        "            x = torch.tensor(w.reshape(1,-1), dtype=torch.float32, device='cuda')\n",
        "            out, h = model(x, h)\n",
        "\n",
        "        loss = loss_fn(out, y_tensor.unsqueeze(0))\n",
        "        testing_loss += loss.item()\n",
        "    \n",
        "    avg_loss = testing_loss / test_count\n",
        "    test_loss.append(avg_loss)\n",
        "    \n",
        "    if e % 100 == 0:\n",
        "        print(e, ' Train Loss: ', run_loss, ' Test Loss: ', avg_loss)      "
      ],
      "execution_count": 75,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "285\n",
            "0  Train Loss:  1.608080075916491  Test Loss:  1.9495830059051513\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-75-20f84a956ba3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    114\u001b[0m         \u001b[0;31m#print('out: ', out)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    115\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_tensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munsqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 116\u001b[0;31m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mretain_graph\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    117\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    118\u001b[0m         \u001b[0mrunning_loss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[1;32m    105\u001b[0m                 \u001b[0mproducts\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0mDefaults\u001b[0m \u001b[0mto\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    106\u001b[0m         \"\"\"\n\u001b[0;32m--> 107\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    108\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    109\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[1;32m     91\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[1;32m     92\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 93\u001b[0;31m         allow_unreachable=True)  # allow_unreachable flag\n\u001b[0m\u001b[1;32m     94\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "arR_4Wnk55Gg",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "d8aaa0c3-fa98-4e4d-f8f8-b1a1c9af185c"
      },
      "source": [
        "y_tensor"
      ],
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[2]], device='cuda:0')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 62
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "beaChE5uYFY4",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "a4ee3035-1672-4698-e3ac-d1e61fd26908"
      },
      "source": [
        "y_tensor.cpu().detach().numpy()[0][0]"
      ],
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 66
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wbqihV-4fkPm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}