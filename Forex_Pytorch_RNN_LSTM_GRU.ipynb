{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Forex Pytorch RNN LSTM GRU.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ballmdr/Forex-Prediction-Machine_Learning/blob/master/Forex_Pytorch_RNN_LSTM_GRU.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GTr87mQimrTu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip install fxcmpy"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KB2wBmhcwl_A",
        "colab_type": "code",
        "outputId": "605e8d4e-dd7d-4dab-833c-10c5526b7886",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 154
        }
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.autograd import Variable\n",
        "from torch.utils.data import DataLoader\n",
        "import fxcmpy\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "sns.set()\n",
        "%matplotlib inline\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "def connect():\n",
        "    return fxcmpy.fxcmpy(access_token=access_token, server=server)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "um-6M_LNw0Rv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "access_token = '82e41ea2bcf020754f67aeb835e9ad617dbc5427'\n",
        "server = 'demo'\n",
        "symbol = 'BTCUSD'\n",
        "symbol2 = 'BTC/USD'\n",
        "target_windows = 5\n",
        "digits = 1\n",
        "ratio = 100\n",
        "n_prices = 10000"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TK4QhqlJ46Ob",
        "colab_type": "code",
        "outputId": "2e32669d-fd4a-43bd-8966-8972bc2d2215",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        }
      },
      "source": [
        "con = connect()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "|WARNING|2019-07-29 02:31:24,411|Default account set to 1041561, to change use set_default_account().\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FFmL-2Xe4p_S",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def dfProcess(df):\n",
        "# Short-Term\n",
        "# ใช้ค่า 3, 5, 8, 10, 12, or 15.\n",
        "# Long-Term\n",
        "# ใช้ค่า 30, 35, 40, 45, 50, or 60.\n",
        "  df['ma3'] = np.round(df.close.rolling(3).mean(), 5)\n",
        "  df['ma5'] = np.round(df.close.rolling(5).mean(), 5)\n",
        "  df['ma8'] = np.round(df.close.rolling(8).mean(), 5)\n",
        "  df['ma10'] = np.round(df.close.rolling(10).mean(), 5)\n",
        "  df['ma12'] = np.round(df.close.rolling(12).mean(), 5)\n",
        "  df['ma15'] = np.round(df.close.rolling(15).mean(), 5)\n",
        "  #df['ma20'] = np.round(df.close.rolling(20).mean(), 5)\n",
        "  #df['ma7_shift3'] = df.ma7.shift(-3)\n",
        "  #df['ma10_shift3'] = df.ma10.shift(-3)\n",
        "  #df['close_shift3'] = df.close.shift(-3)\n",
        "  df['close_diff_pip'] = - df.close.diff(-target_windows) * digits\n",
        "  \n",
        "  arr = ['0', '1', '2', '3', '4']\n",
        "  for i in range(1, target_windows):\n",
        "    df[arr[i]] = - df.close.diff(-i) * digits\n",
        "    \n",
        "  df.dropna(inplace=True)\n",
        "\n",
        "  #df['close_target_percent'] = np.round((df['close_diff_pip']*digits)/df.close, 2) * 100\n",
        "  #df['7_10_target_percent'] = np.round(((df['ma7_shift3']-df['ma10_shift3'])*digits)/df['ma10_shift3'], 2)\n",
        "  #df['5_7_target_percent'] = np.round(((df.ma5-df.ma7)*digits)/df.ma7, 2)\n",
        "  \n",
        "\n",
        "  df['Target'] = np.ones(len(df))\n",
        "  # df['Target'].loc[(df['close_target_percent'] > 9) & (df['7_10_target_percent'] > 1) & (df['5_7_target_percent'] > 1)] = 2\n",
        "  # df['Target'].loc[(df['close_target_percent'] < -9) & (df['7_10_target_percent'] < -1) & (df['5_7_target_percent'] < -1)] = 0\n",
        "  df['Target'].loc[(df['close_diff_pip'] > ratio) &\n",
        "                   (df['1'] > -ratio) &\n",
        "                   (df['2'] > -ratio) &\n",
        "                   (df['3'] > -ratio) &\n",
        "                   (df['4'] > -ratio)\n",
        "                  ] = 2\n",
        "  df['Target'].loc[(df['close_diff_pip'] < -ratio) &\n",
        "                   (df['1'] < ratio) &\n",
        "                   (df['2'] < ratio) &\n",
        "                   (df['3'] < ratio) &\n",
        "                   (df['4'] < ratio)                    \n",
        "                  ] = 0\n",
        "  print(df.Target.value_counts())\n",
        "\n",
        "  df.drop(['bidopen', 'bidclose', 'bidhigh', 'askopen', 'askclose', 'askhigh', 'bidlow', 'asklow', 'tickqty', 'close_diff_pip', '1', '2', '3', '4'], axis=1, inplace=True)\n",
        "  df.dropna(inplace=True)\n",
        "  print(df.head())\n",
        "  print(df.shape)\n",
        "  \n",
        "  print(df.info())\n",
        "  \n",
        "  return df\n",
        "\n",
        "\n",
        "def getXY(df, windows):\n",
        "\n",
        "  X = []\n",
        "  Y = []\n",
        "  for i in range(len(df)-(windows+1)):\n",
        "    \n",
        "\n",
        "    fig = plt.figure(frameon=False) \n",
        "    fig.set_size_inches(3,2)\n",
        "    ax = plt.Axes(fig, [0., 0., 1., 1.])\n",
        "    ax.set_axis_off()\n",
        "    fig.add_axes(ax)\n",
        "\n",
        "    _df = df.iloc[i:windows]\n",
        "    plt.plot(_df.ma3, color='red')\n",
        "    plt.plot(_df.ma5, color='blue')\n",
        "    plt.plot(_df.ma8, color='green')\n",
        "    plt.plot(_df.ma10, color='orange')\n",
        "    plt.plot(_df.ma12, color='black')\n",
        "    plt.plot(_df.ma15, color='purple')\n",
        "    #plt.plot(_df.open, color='black')\n",
        "   # plt.plot(_df.close, color='purple')\n",
        "\n",
        "    plt.savefig('tmp2.png')\n",
        "\n",
        "    plt.close()\n",
        "\n",
        "    img = plt.imread('tmp2.png')\n",
        "    new_img = resize(img, (100,150))\n",
        "    #print(new_img.shape)\n",
        "    if i % 1000 == 0:\n",
        "      print(i)\n",
        "      plt.imshow(new_img)\n",
        "      plt.show()\n",
        "      print(i, ' - ', windows)\n",
        "      print('target: ', df.Target.iloc[windows-1])\n",
        "    X.append(new_img)\n",
        "    Y.append(df.Target.iloc[windows-1])\n",
        "\n",
        "    windows += 1\n",
        "\n",
        "  return X, Y\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SnqjLTdB4rRQ",
        "colab_type": "code",
        "outputId": "dd897127-3dbd-417a-a948-bad5831ca2e0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 686
        }
      },
      "source": [
        "df = con.get_candles(symbol2, period='H4', number=n_prices)\n",
        "df['close'] = (df.bidclose + df.askclose) / 2\n",
        "df = dfProcess(df)\n",
        "\n",
        "#df['close'] = (df.close - df.close.mean()) / (df.close.max() - df.close.min())\n",
        "#print(df['close'].head())\n",
        "\n",
        "split = int(len(df) * 0.60)\n",
        "train_data = df.iloc[:split].drop(['Target'], axis=1).values\n",
        "train_target = df.iloc[:split]['Target'].values\n",
        "test_data = df.iloc[split:].drop(['Target'], axis=1).values\n",
        "test_target = df.iloc[split:]['Target'].values\n",
        "\n",
        "\n",
        "minmax = MinMaxScaler()\n",
        "train_data = minmax.fit_transform(train_data)\n",
        "test_data = minmax.transform(test_data)\n",
        "print(train_data.shape)\n",
        "print(train_target.shape)\n",
        "print(test_data.shape)\n",
        "print(test_target.shape)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1.0    925\n",
            "2.0    390\n",
            "0.0    327\n",
            "Name: Target, dtype: int64\n",
            "                      close         ma3     ma5  ...        ma12        ma15  Target\n",
            "date                                             ...                                \n",
            "2018-06-27 15:00:00  6105.0  6097.00000  6107.2  ...  6183.95833  6180.70000     1.0\n",
            "2018-06-27 19:00:00  6142.5  6118.50000  6102.7  ...  6171.87500  6180.86667     1.0\n",
            "2018-06-28 00:00:00  6135.0  6127.50000  6113.7  ...  6159.95833  6180.20000     1.0\n",
            "2018-06-28 04:00:00  6132.5  6136.66667  6124.6  ...  6150.33333  6174.50000     0.0\n",
            "2018-06-28 08:00:00  6110.0  6125.83333  6125.0  ...  6138.83333  6162.66667     0.0\n",
            "\n",
            "[5 rows x 8 columns]\n",
            "(1642, 8)\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "DatetimeIndex: 1642 entries, 2018-06-27 15:00:00 to 2019-07-26 05:00:00\n",
            "Data columns (total 8 columns):\n",
            "close     1642 non-null float64\n",
            "ma3       1642 non-null float64\n",
            "ma5       1642 non-null float64\n",
            "ma8       1642 non-null float64\n",
            "ma10      1642 non-null float64\n",
            "ma12      1642 non-null float64\n",
            "ma15      1642 non-null float64\n",
            "Target    1642 non-null float64\n",
            "dtypes: float64(8)\n",
            "memory usage: 115.5 KB\n",
            "None\n",
            "(985, 7)\n",
            "(985,)\n",
            "(657, 7)\n",
            "(657,)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/pandas/core/indexing.py:190: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
            "  self._setitem_with_indexer(indexer, value)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fvLWgkJ9k9VI",
        "colab_type": "code",
        "outputId": "67b9e6ec-29e3-46ec-8971-8557ea6faa71",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 292
        }
      },
      "source": [
        "train_data[0:5]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[1.60214413e-02, 5.87354478e-04, 0.00000000e+00, 0.00000000e+00,\n",
              "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 4.12435766e-01,\n",
              "        3.29394387e-01, 3.92737430e-01, 5.81753890e-01, 5.34142640e-01],\n",
              "       [0.00000000e+00, 0.00000000e+00, 2.83960092e-02, 1.73719686e-02,\n",
              "        1.41249952e-02, 1.22750490e-02, 1.06621397e-02, 4.70914697e-01,\n",
              "        4.22451994e-01, 5.65921788e-01, 6.10183876e-01, 5.24911482e-01],\n",
              "       [2.15008934e-02, 2.67347187e-03, 6.00222220e-02, 3.71134737e-02,\n",
              "        3.00211323e-02, 2.60192593e-02, 2.24959834e-02, 4.73175745e-01,\n",
              "        5.12555391e-01, 5.06005587e-01, 5.10749646e-01, 5.17197774e-01],\n",
              "       [7.93329363e-02, 2.42030210e-02, 7.49475951e-02, 6.34632757e-02,\n",
              "        5.11644845e-02, 4.38322699e-02, 3.69177968e-02, 4.36690647e-01,\n",
              "        3.59084195e-01, 3.22625698e-01, 4.15841584e-01, 4.42842691e-01],\n",
              "       [7.52829065e-02, 4.98035411e-02, 8.68031294e-02, 8.94725870e-02,\n",
              "        7.18222899e-02, 6.11509810e-02, 5.13213601e-02, 3.33093525e-01,\n",
              "        3.18611521e-01, 3.74022346e-01, 4.79632249e-01, 5.29337380e-01]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0JbbgfUglT-m",
        "colab_type": "code",
        "outputId": "62b1f845-e631-4ae9-af01-59d60ab6f268",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 235
        }
      },
      "source": [
        "df.iloc[0:5]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>close</th>\n",
              "      <th>ma3</th>\n",
              "      <th>ma5</th>\n",
              "      <th>ma8</th>\n",
              "      <th>ma10</th>\n",
              "      <th>ma12</th>\n",
              "      <th>ma15</th>\n",
              "      <th>close_diff_pip</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>Target</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>date</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>2019-04-02 10:00:00</th>\n",
              "      <td>4810.00</td>\n",
              "      <td>4579.66667</td>\n",
              "      <td>4402.45</td>\n",
              "      <td>4298.81250</td>\n",
              "      <td>4260.050</td>\n",
              "      <td>4231.72917</td>\n",
              "      <td>4192.33333</td>\n",
              "      <td>176.25</td>\n",
              "      <td>10.00</td>\n",
              "      <td>-57.25</td>\n",
              "      <td>102.75</td>\n",
              "      <td>275.75</td>\n",
              "      <td>2.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2019-04-02 14:00:00</th>\n",
              "      <td>4820.00</td>\n",
              "      <td>4796.66667</td>\n",
              "      <td>4538.90</td>\n",
              "      <td>4385.34375</td>\n",
              "      <td>4332.825</td>\n",
              "      <td>4291.89583</td>\n",
              "      <td>4246.36667</td>\n",
              "      <td>163.25</td>\n",
              "      <td>-67.25</td>\n",
              "      <td>92.75</td>\n",
              "      <td>265.75</td>\n",
              "      <td>166.25</td>\n",
              "      <td>2.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2019-04-02 18:00:00</th>\n",
              "      <td>4752.75</td>\n",
              "      <td>4794.25000</td>\n",
              "      <td>4662.35</td>\n",
              "      <td>4464.71875</td>\n",
              "      <td>4396.325</td>\n",
              "      <td>4347.77083</td>\n",
              "      <td>4295.05000</td>\n",
              "      <td>305.50</td>\n",
              "      <td>160.00</td>\n",
              "      <td>333.00</td>\n",
              "      <td>233.50</td>\n",
              "      <td>230.50</td>\n",
              "      <td>2.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2019-04-02 23:00:00</th>\n",
              "      <td>4912.75</td>\n",
              "      <td>4828.50000</td>\n",
              "      <td>4811.10</td>\n",
              "      <td>4562.21875</td>\n",
              "      <td>4474.825</td>\n",
              "      <td>4416.14583</td>\n",
              "      <td>4351.08333</td>\n",
              "      <td>241.50</td>\n",
              "      <td>173.00</td>\n",
              "      <td>73.50</td>\n",
              "      <td>70.50</td>\n",
              "      <td>145.50</td>\n",
              "      <td>2.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2019-04-03 03:00:00</th>\n",
              "      <td>5085.75</td>\n",
              "      <td>4917.08333</td>\n",
              "      <td>4876.25</td>\n",
              "      <td>4680.71875</td>\n",
              "      <td>4571.625</td>\n",
              "      <td>4496.81250</td>\n",
              "      <td>4416.93333</td>\n",
              "      <td>222.25</td>\n",
              "      <td>-99.50</td>\n",
              "      <td>-102.50</td>\n",
              "      <td>-27.50</td>\n",
              "      <td>68.50</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                       close         ma3      ma5  ...       3       4  Target\n",
              "date                                               ...                        \n",
              "2019-04-02 10:00:00  4810.00  4579.66667  4402.45  ...  102.75  275.75     2.0\n",
              "2019-04-02 14:00:00  4820.00  4796.66667  4538.90  ...  265.75  166.25     2.0\n",
              "2019-04-02 18:00:00  4752.75  4794.25000  4662.35  ...  233.50  230.50     2.0\n",
              "2019-04-02 23:00:00  4912.75  4828.50000  4811.10  ...   70.50  145.50     2.0\n",
              "2019-04-03 03:00:00  5085.75  4917.08333  4876.25  ...  -27.50   68.50     1.0\n",
              "\n",
              "[5 rows x 13 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8NjP2vbelnu9",
        "colab_type": "code",
        "outputId": "c14870b7-c9db-4d5b-9fc1-98ec92658cd5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "train_data[0:5][0].reshape(1,-1).shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1, 12)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V1tKxr2nyyu9",
        "colab_type": "code",
        "outputId": "558c2f6c-c9bb-4e08-fa9f-125a2dfd6403",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 272
        }
      },
      "source": [
        "class RNN(nn.Module):\n",
        "    def __init__(self, hidden, K, input_size):\n",
        "        super(RNN, self).__init__()\n",
        "        \n",
        "        self.linearH = nn.Linear(input_size + hidden, hidden)\n",
        "        self.linearO = nn.Linear(input_size + hidden, K)\n",
        "        self.softmax = nn.LogSoftmax(dim=1)\n",
        "        \n",
        "    def forward(self, x, h):\n",
        "        x = torch.cat((x, h), 1)\n",
        "        h = torch.tanh(self.linearH(x))\n",
        "        out = self.softmax(self.linearO(x))\n",
        "        \n",
        "        return out, h\n",
        "      \n",
        "      \n",
        "class LSTM(nn.Module):\n",
        "  def __init__(self, hidden, output_size, vocab_size, n_layers):\n",
        "    super(LSTM, self).__init__()\n",
        "    self.n_layers = n_layers\n",
        "    \n",
        "    self.linearFt = nn.Linear(vocab_size + hidden*2, hidden)\n",
        "    self.linearIt = nn.Linear(vocab_size + hidden*2, hidden)\n",
        "    self.linearCt1 = nn.Linear(vocab_size + hidden*2, hidden)\n",
        "    self.linearOt = nn.Linear(vocab_size + hidden*2, hidden)\n",
        "    self.linearO = nn.Linear(vocab_size + hidden*2, output_size)\n",
        "    self.drop = nn.Dropout(p=0.50)\n",
        "    self.softmax = nn.LogSoftmax(dim=1)\n",
        "    \n",
        "  def forward(self, x, h, c):\n",
        "    \n",
        "    for n in range(self.n_layers):\n",
        "      combined = torch.cat((x, h, c), 1)\n",
        "      ft = torch.sigmoid(self.linearFt(combined))\n",
        "      it = torch.sigmoid(self.linearIt(combined))\n",
        "      ct1 = torch.tanh(self.linearCt1(combined))\n",
        "      c = (ft*c) + (it * ct1)\n",
        "      #c = (ft*c) + (1-ft) * ct1\n",
        "      c = self.drop(c)\n",
        "\n",
        "      ot = torch.sigmoid(self.linearOt(combined))\n",
        "      h = ot * torch.tanh(c)\n",
        "      h = self.drop(h)\n",
        "\n",
        "      out = self.softmax(self.linearO(combined))\n",
        "    \n",
        "    return out, h, c\n",
        "\n",
        "  \n",
        "class GRU(nn.Module):\n",
        "  \n",
        "  def __init__(self, hidden, output_size, input_size):\n",
        "    super(GRU, self).__init__()\n",
        "    \n",
        "    use_bias = True\n",
        "    \n",
        "    self.linearZt = nn.Linear(input_size + hidden, hidden, bias=use_bias)\n",
        "    self.linearRt = nn.Linear(input_size + hidden, hidden, bias=use_bias)\n",
        "    self.linearHt = nn.Linear(input_size + hidden, hidden, bias=use_bias)\n",
        "    \n",
        "    self.normH = nn.BatchNorm1d(input_size + hidden)\n",
        "    self.drop1 = nn.Dropout(p=0.50)\n",
        "    self.drop2 = nn.Dropout(p=0.25)\n",
        "    \n",
        "    self.linearO = nn.Linear(input_size + hidden, output_size, bias=use_bias)\n",
        "    self.normO = nn.BatchNorm1d(input_size + hidden)\n",
        "    \n",
        "    self.softmax = nn.LogSoftmax(dim=1)\n",
        "    \n",
        "  def forward(self, x, h):\n",
        "    combined = torch.cat((x, h), 1)\n",
        "    zt = torch.sigmoid(self.linearZt(combined))\n",
        "    zt = self.drop1(zt)\n",
        "    rt = torch.sigmoid(self.linearRt(combined))\n",
        "    rt = self.drop1(rt)\n",
        "    combined2 = torch.cat((x, rt*h), 1)\n",
        "    ht = torch.tanh(self.linearHt(combined2))\n",
        "    ht = self.drop1(ht)\n",
        "    h = (1-zt) * h + zt * ht\n",
        "    h = self.drop2(h)\n",
        "    \n",
        "    out = self.linearO(combined)\n",
        "    out = self.softmax(out)\n",
        "  \n",
        "    return out, h\n",
        "  \n",
        "windows = 6\n",
        "input_size = train_data.shape[1]\n",
        "hidden = 8\n",
        "n_layers = 1\n",
        "K = 3\n",
        "learning_rate = 0.05\n",
        "epochs = 8000\n",
        "train_loss = []\n",
        "test_loss = []\n",
        "\n",
        "\n",
        "model = LSTM(hidden, K, input_size, n_layers)\n",
        "model.cuda()\n",
        "loss_fn = nn.NLLLoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
        "scheduler = torch.optim.lr_scheduler.MultiStepLR(optimizer, milestones=[100, 200, 400, 800, 1600, 3200, 6400], gamma=0.1)\n",
        "#scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=200, gamma=0.1)\n",
        "N = len(train_data)-(windows+1)\n",
        "batch_size = 32\n",
        "\n",
        "x_train = DataLoader(train_data, batch_size=batch_size, shuffle=False, pin_memory=True)\n",
        "y_train = DataLoader(train_target, batch_size=batch_size, shuffle=False, pin_memory=True)\n",
        "\n",
        "for e in range(epochs):\n",
        "    model.train()\n",
        "    running_loss = 0.0\n",
        "    testing_loss = 0.0\n",
        "    \n",
        "    for i in range(N):\n",
        "      \n",
        "    #for i in range(batch_size):\n",
        "      \n",
        "        index = np.random.randint(0, N)\n",
        "        \n",
        "        #inputs = train_data[i:i+windows]\n",
        "        #y = train_target[(i+windows)-1]\n",
        "        #\n",
        "        \n",
        "        inputs = train_data[index:index+windows]\n",
        "        #print(inputs)\n",
        "        \n",
        "        y = train_target[(index+windows)-1]\n",
        "        y_tensor = torch.tensor(y, dtype=torch.long).cuda()\n",
        "\n",
        "        #print(i, ' Input: ', inputs, ' Target: ', y, ' ', train_data[windows-1])\n",
        "\n",
        "        h = torch.zeros([1, hidden], dtype=torch.float32).cuda()\n",
        "        c = torch.zeros([1, hidden], dtype=torch.float32).cuda()\n",
        "\n",
        "        #print('y: ', y_tensor)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        for w in range(len(inputs)):\n",
        "          #print(w)\n",
        "          x = torch.tensor(inputs[w].reshape(1,-1), dtype=torch.float32).cuda()\n",
        "          out, h, c = model(x, h, c)\n",
        "\n",
        "        #print('out: ', out)\n",
        "        loss = loss_fn(out, y_tensor.unsqueeze(0))\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        running_loss += loss.item()\n",
        "        \n",
        "    run_loss = running_loss / N\n",
        "    train_loss.append(run_loss)\n",
        "    scheduler.step()\n",
        "\n",
        "    model.eval()\n",
        "    test_count = 100\n",
        "    for j in range(test_count):\n",
        "        index = np.random.randint(0, len(test_data)-(windows+1))\n",
        "        #print('index: ', index)\n",
        "        h = torch.zeros([1, hidden], dtype=torch.float32).cuda()\n",
        "        c = torch.zeros([1, hidden], dtype=torch.float32).cuda()\n",
        "        \n",
        "        inputs = test_data[index:index+windows]\n",
        "        y = test_target[(index+windows)-1]\n",
        "        y_tensor = torch.tensor(y, dtype=torch.long).cuda()\n",
        "\n",
        "        for w in range(len(inputs)):\n",
        "            x = torch.tensor(inputs[w].reshape(1,-1), dtype=torch.float32).cuda()\n",
        "            out, h, c = model(x, h, c)\n",
        "\n",
        "        loss = loss_fn(out, y_tensor.unsqueeze(0))\n",
        "        testing_loss += loss.item()\n",
        "    \n",
        "    avg_loss = testing_loss / test_count\n",
        "    test_loss.append(avg_loss)\n",
        "    \n",
        "    if e % 10 == 0:\n",
        "        print(e, ' Train Loss: ', run_loss, ' Test Loss: ', avg_loss)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1740  Train Loss:  0.9132045409308864  Test Loss:  1.0699397844076157\n",
            "1750  Train Loss:  0.9233357320655831  Test Loss:  1.0914690434932708\n",
            "1760  Train Loss:  0.9365025439389156  Test Loss:  0.9963647955656052\n",
            "1770  Train Loss:  0.908079128933343  Test Loss:  1.0304762428998948\n",
            "1780  Train Loss:  0.9584344475547228  Test Loss:  1.0123466813564301\n",
            "1790  Train Loss:  0.8779223944329045  Test Loss:  0.9995336127281189\n",
            "1800  Train Loss:  0.9193265275355497  Test Loss:  0.9730107337236404\n",
            "1810  Train Loss:  0.9123293926257541  Test Loss:  1.036050118803978\n",
            "1820  Train Loss:  0.9258117510619095  Test Loss:  1.1024001961946488\n",
            "1830  Train Loss:  0.9048807621002197  Test Loss:  1.0770631867647171\n",
            "1840  Train Loss:  0.8609009837628874  Test Loss:  0.986560692191124\n",
            "1850  Train Loss:  0.928529107131841  Test Loss:  1.0476224154233933\n",
            "1860  Train Loss:  0.8955481730112025  Test Loss:  1.1205168014764786\n",
            "1870  Train Loss:  0.9292904150449425  Test Loss:  1.0904557812213898\n",
            "1880  Train Loss:  0.9020484095945924  Test Loss:  1.0779274147748947\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "arR_4Wnk55Gg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "plt.plot(train_loss, label='Train')\n",
        "plt.plot(test_loss, label='Test')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "beaChE5uYFY4",
        "colab_type": "code",
        "outputId": "a4ee3035-1672-4698-e3ac-d1e61fd26908",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "y_tensor.cpu().detach().numpy()[0][0]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 66
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wbqihV-4fkPm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}